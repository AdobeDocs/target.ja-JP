---
keywords: AB;A/B;AB...n;sample size;sample size calculator;auto-allocate;auto allocate;calculator
description: A/B テストを成功させるにはコンバージョン率を向上させるのに十分な数の訪問者（サンプルサイズ）が必要ですが、A/B テストを実行すべき期間はどのようにすれば知ることができますか？この記事には、目標を達成するのに十分な数の訪問者をアクティビティに確実に持たせるために役立つ、自動配分アクティビティとAdobe Targetのサンプルサイズ計算ツールに関する情報が含まれています。
title: A/B テストを実行すべき期間はどのくらいですか？
feature: ab
uuid: 4f5693c8-5372-425b-8e61-efb595b144cc
translation-type: tm+mt
source-git-commit: 95450abc32be19d04b791af3c62673e9411ab53c
workflow-type: tm+mt
source-wordcount: '3102'
ht-degree: 75%

---


# A/B テストを実行すべき期間はどのくらいですか？

A successful [!UICONTROL A/B Test] activity requires an adequate number of visitors (sample size) to improve your conversion rate, but how do you know how long to run an A/B test? This article contains information about [!UICONTROL Auto-Allocate] activities and the [!UICONTROL Adobe Target] Sample Size Calculator to help you ensure that your activity has a sufficient number of visitors to achieve your goals.

アクティビティの最初の数日でオファーの 1 つのパフォーマンスが他に比べてずっと優れている、または劣っている場合、アクティビティを停止したくなります。ただし、観測結果の数が少ない場合、コンバージョン率は少ない訪問者数の平均なので、まったく偶然にプラスまたはマイナスの上昇が観測される可能性が高いです。アクティビティでより多くのデータポイントを収集するに従って、コンバージョン率は真の長期的な値に近づきます。

>[!IMPORTANT]
>
>アクティビティを早期に停止することは、A/Bテストを実行する際に悪影響を及ぼす可能性のある、10個の重要な落とし穴の1つです。 詳しくは、 [10件の一般的なA/Bテストの落とし穴とそれらの回避方法を参照してください](/help/c-activities/t-test-ab/common-ab-testing-pitfalls.md#concept_578A7947C9554868B30F12DFF9E3F8E3)。

[!DNL Target] には、コンバージョン目標を達成するのに十分なサンプルサイズをアクティビティに確実に持たせるためのツールが用意されています。自動配分を参照してください。

## 自動配分 {#auto-allocate}

An [Auto-Allocate](/help/c-activities/automated-traffic-allocation/automated-traffic-allocation.md) activity is a type of A/B test that identifies a winner among two or more experiences and automatically reallocates more traffic to the winner to increase conversions while the test continues to run and learn.

標準的な A/B テストには、固有のコストがあります。各エクスペリエンスのパフォーマンスを測定するためにトラフィックを費やす必要があり、分析を通じて勝者エクスペリエンスを見つけ出す必要があります。トラフィックの配分は、一部のエクスペリエンスが他よりもパフォーマンスに優れているとわかった後でも、固定されたままです。また、サンプルサイズの計算が複雑で、アクティビティは、勝者に対して働きかけられるようになる前に全コースを実行する必要があります。これをすべておこなった後でも、特定した勝者が真の勝者ではない可能性があります。

The solution is [!UICONTROL Auto-Allocate]. [!UICONTROL 自動配分は、このコストおよび勝者エクスペリエンスの判別のオーバーヘッドを削減します。][!UICONTROL 自動配分では、すべてのエクスペリエンスの目標指標パフォーマンスを監視し、パフォーマンスの高いエクスペリエンスに、パフォーマンスの高さに応じて多くの新規参加者を送ります。]他のエクスペリエンスを調査するのに十分なトラフィックが予約されます。アクティビティがまだ実行中でも、結果に対するアクティビティのメリットを確認できます。最適化は、学習と並行して行われます。

[!UICONTROL 自動配分は、アクティビティが終了して勝者が決まるまで待たずに、訪問者を徐々に勝者エクスペリエンスに近づけます。]成功していないエクスペリエンスに送られたアクティビティ参加者は勝者エクスペリエンスの可能性を示しているので、より迅速に上昇するメリットが得られます。

[!UICONTROL 自動配分]機能を使用すると、[!DNL Target] は、アクティビティが十分な信頼性のあるコンバージョンの最低数に達するまで、アクティビティのページの最上部に「まだ勝者がありません」ということを示すバッジを表示します。[!DNL Target]次に、 は、アクティビティのページの上部にバッジを表示して、勝者エクスペリエンスを宣言します。

For more information, see [Auto-Allocate overview](/help/c-activities/automated-traffic-allocation/automated-traffic-allocation.md).

## Adobe Target サンプルサイズ計算ツール {#section_6B8725BD704C4AFE939EF2A6B6E834E6}

If you choose to use a manual [!UICONTROL A/B Test] activity rather than [!UICONTROL Auto-Allocate], the [!DNL Target] Sample Size Calculator helps you determine the sample size needed for a successful test. 手動のA/Bテストは、固定水平線テストなので、計算ツールは非常に役立ちます。 自動配分 [!UICONTROL アクティビティの計算ツールの使用はオプションです。] 自動配分では勝者が [!UICONTROL 宣言されるので] 、自動配分(Auto-Allocate)は任意です。 計算ツールを使用すると、必要なサンプルサイズを概算できます。 計算ツールの使い方について詳しくは、以降の節を参照してください。

Before setting up your A/B test, access the Adobe Target [sample size calculator](https://docs.adobe.com/content/target-microsite/testcalculator.html).

![Adobe Target サンプルサイズ計算ツール](/help/c-activities/t-test-ab/assets/sample_size_calculator-new.png)

結果を評価する前にアクティビティを実行する時間を確立するために、A/Bテストを実行する前に、適切なサンプルサイズ(訪問者数)を決定することが重要です。 統計的有意性が達成されるまでアクティビティを監視するだけで、信頼区間が大幅に低く見積もられ、信頼できないテストになります。 この場合、統計的に有意な結果が検出された時点でテストは停止して、勝者が宣言されます。ただし、結果が統計的に有意でない場合は、テストの続行が許可されます。この方法では、前向きな結果に大きく偏向して偽陽性率が高くなるので、テストの有効有意水準にゆがみが生じます。

この場合、偽陽性が大量に発生する可能性があり、予測された上昇率が長期的に持続しないオファーを誤って実装してしまうことにつながります。不十分な上昇率そのものは不満を満たす結果ですが、さらに深刻な結果は、上昇率を正確に予測できないことで、プラクティスとしてのテストで組織の信頼が徐々に低下することです。

この記事では、サンプルサイズを決定するときにバランスを取る必要がある要因について説明し、十分なサンプルサイズを見積もるために使用するスプレッドシート計算表を紹介します。A/B テストを始める前にサンプルサイズ計算ツール（前述のリンク参照）を使用してサンプルサイズを計算すると、統計基準に準拠した高品質な A/B テストを常におこなうことができます。

A/B テストを定義する 5 つのユーザー定義パラメーターがあります。これらのパラメーターは関連しているので、4 つが定まると、5 つ目のパラメーターを計算できます。

* 統計的有意性
* 統計的検出力
* 最小信頼検出可能上昇率
* ベースラインコンバージョン率
* 訪問者数

A/B テストの場合、統計的有意性、統計的検出力、最小信頼検出可能上昇率およびベースラインコンバージョン率は、アナリストが設定し、必要な訪問者数は、これらの数字から計算されます。この記事では、これらの要素について説明し、特定のテストに対してこれらの要素を決定する方法のガイドラインを示します。

![](assets/samplesize.png)

下の図に、A/B テストの考えられる 4 つの結果を示します。

![](assets/outcomes.png)

偽陽性または偽陰性はないのが望ましいです。ただし、それを統計テストによって保証することはできません。観察傾向が基本的なコンバージョン率を表していない可能性は常にあります。例えば、コインの表または裏のどちらが高いかを調べるテストでは、フェアなコインを使用しても、偶然に10回表を10回表示できます。 統計的有意性と統計的検出力によって、偽陽性率と偽陰性率を定量化して、特定のテストでこれらの率を適度なレベルに維持することができます。

### 統計的有意性 {#section_8230FB9C6D1241D8B1786B72B379C3CD}

テストの有意水準は、異なる2つのオファー間で、実際にはコンバージョン率に違いがない場合に、その違いがレポートされる可能性を決定します。 これは、偽陽性または第一種過誤と呼ばれます。有意水準はユーザーが指定するしきい値で、偽陽性の許容値とテストに含める必要がある訪問者数とのトレードオフを示します。

A/B テストでは、当初、どちらのオファーもコンバージョン率は同じであると想定します。その後、この想定に基づいて観察結果の確率が計算されます。If this probability (the p-value) is smaller than some predefined threshold (the significance level), [!DNL Target] concludes that the initial assumption--that both offers have the same conversion rate--is incorrect and, therefore, the conversion rates of A and B are statistically different at the given significance level.

A/B テストで一般的に使用される有意水準は 5％です。これは、信頼水準 95％（信頼水準＝100％ - 有意水準）に相当します。信頼水準 95％とは、毎回のテストでオファー間に違いがない場合でも、統計的に有意な上昇率が 5％の確率で見つかるという意味です。

信頼水準の一般的な解釈を下の表にまとめます。

| 信頼水準 | 解釈 |
|--- |--- |
| &lt; 90％ | コンバージョン率に違いがあるとする証拠がない。 |
| 90 ～ 95％ | コンバージョン率に違いがあるとする薄弱な証拠。 |
| 95 ～ 99％ | コンバージョン率に違いがあるとする中程度の証拠。 |
| 99 ～ 99.9％ | コンバージョン率に違いがあるとする強力な証拠。 |
| +99.9％ | コンバージョン率に違いがあるとするきわめて強力な証拠。 |

常に 95％以上の信頼水準を使用することをお勧めします。

できるだけ高い信頼水準を使用して偽陽性をほとんど発生させないのが望ましいです。ただし、信頼水準が高くなると、それだけ必要となる訪問者数が増え、テストの実施に要する時間も長くなります。また、信頼水準が高くなると、統計的検出力が低下します。

### 統計的検出力 {#section_1169C27F8E4643719D38FB9D6EBEB535}

A/B テストの統計的検出力は、ある特定の規模におけるコンバージョン率の実際の違いを検出する確率です。コンバージョンイベントのランダム性（確率性）のため、2 つのオファー間で実際にはコンバージョン率に違いあっても、統計的に有意な違いは観察されない（単なる偶然と見なされる）可能性があります。これは、偽陰性または第二種過誤と呼ばれます。

統計的有意性とは対照的に、A/B テストをおこなうために統計的検出力の決定は必要ないので、統計的検出力は一般的には無視されます。ただし、統計的検出力を無視すると、サンプルサイズが非常に小さいので、異なるオファーのコンバージョン率に存在する実際の違いがテストで検出されない可能性が大幅に高まります。その結果、テストで偽陽性が大量に発生します。

高い統計的検出力を使用することで、実際のコンバージョン率の違いを識別する可能性を高くして、偽陰性をほとんど発生させないことが望ましいです。ただし、ある特定の上昇率を検出する統計的検出力を高めるには、より多くの訪問者数が必要となるので、テストの実施に要する時間が長くなります。

統計的検出力のために一般的に使用される値は 80％です。これは、テストで最小信頼検出可能上昇率と同等の違いが検出される可能性が 80％であるという意味です。テストでは、より低い上昇率を検出する確率が下がり、より高い上昇率を検出する確率が上がります。

### 最小信頼検出可能上昇率 {#section_6101367EE9634C298410BBC2148E33A9}

上昇率が低くても実装する価値はあるので、ほとんどの組織は、コンバージョン率のわずかな違いでも検出することを望んでいます。ただし、A/B テストできわめて低い上昇率を高い確率で検出しようとすると、テストに含める訪問者の数が法外に多くなります。その理由は、コンバージョン率の違いが小さい場合は、コンバージョン率の違いを識別できるだけの高い精度で両方のコンバージョン率を見積もる必要があり、そのためには大量の訪問者が必要となるからです。したがって、低い上昇率を検出することと、テストの実施に要する時間が長くなることとの間のトレードオフを考慮したビジネス要件によって、最小信頼検出可能上昇率を決定する必要があります。

例えば、2 つのオファー（A と B）の真のコンバージョン率がそれぞれ 10％と 15％であるとします。これらのオファーがそれぞれ 100 人の訪問者に示される場合、コンバージョンの確率的な性質のため、95％の確率で、オファー A については 4 ～ 16％の範囲のコンバージョン率が、オファー B については 8 ～ 22％の範囲のコンバージョン率が観察されます。これらの範囲は、統計学的には信頼区間と呼ばれます。これらは、コンバージョン率の見積もり精度の信頼性を表します。サンプルサイズが大きくなれば（訪問者数が多くなれば）、コンバージョン率の見積もりの精度に対する信頼性は高くなります。

下の図は、これらの確率分布を示しています。

![](assets/probability_distributions.png)

2 つの範囲間で重複する部分が大きいので、このテストによって、コンバージョン率が異なるかどうかを判定することはできません。したがって、この 100 人の訪問者を含むテストでは、2 つのオファーを区別できません。ただし、それぞれのオファーを 5,000 人の訪問者に公開すると、95％の確率でそれぞれ 9 ～ 11％と 14 ～ 16％の範囲のコンバージョン率が観察されます。

![](assets/probability_distributions2.png)

この場合、テストから誤った結論が導かれる可能性はきわめて低いので、この 5,000 人の訪問者を含むテストでは 2 つのオファーを区別できます。この 5,000 人の訪問者を含むテストの信頼区間は約 +/-1％です。これは、このテストでは約 1％の違いを検出できるという意味です。したがって、例えば、これらのオファーの真のコンバージョン率が 10％と 15％ではなく、10％と 10.5％の場合は、さらに多くの訪問者が必要になります。

### ベースラインコンバージョン率 {#section_39380C9CA3C649B6BE6E1F8A06178B05}

ベースラインコンバージョン率は、制御オファー（オファー A）のコンバージョン率です。一般に、以前の経験に基づくオファーのコンバージョンレベルは正しく判断できます。それが当てはまらない場合、例えば、新しい種類のオファーまたはクリエイティブの場合は、テストを 1 日ぐらいかけておこなって、サンプルサイズの計算に使用できるベースラインコンバージョン率の大まかな見積もりを得ることができます。

### 訪問者数 {#section_19009F165505429E95291E6976E498DD}

テストを長時間実行する機会費用と偽陽性や偽陰性のリスクとのバランスを取るのは難しい場合があります。判断を誤ることは望ましくありませんが、テスト基準が厳密すぎて麻痺してしまうことも望ましくありません。

一般的なガイドラインとして、信頼水準 95％と統計的検出力 80％をお勧めします。

サンプルサイズ計算ツール（前述のリンク参照）を使用すると、統計的有意性（推奨値 95％）と統計的検出力（推奨値 80％）を決定できます。すべてのオファー全体を対象としたベースラインコンバージョン率と毎日のトラフィックを入力すると、テストの指定された統計的検出力と同等の確率で上昇率 1％、2％、5％、10％、15％および 20％を検出するために必要な訪問者の数が出力されます。また、このスプレッドシートには、最小信頼検出可能上昇率のカスタム値を入力することもできます。さらに、ユーザーが入力したトラフィックレベルに基づいてテストをおこなうために必要な週数も出力されます。必要な週数は、結果に影響する曜日効果を避けるために直近の一週間に切り上げられます。

テストによって確実に識別できる最小上昇率と、必要な訪問者数との間にトレードオフがあります。下の図は、ベースライン（制御）コンバージョン率 5％に対して有効で、訪問者数の増加に対する顕著な収穫逓減を示しています。確実に検出できる最小上昇率は、最初に少数の訪問者を追加すると著しく向上しますが、テストを向上させるために徐々に訪問者数が増えていきます。この図は、テストの実施に要する時間（必要な訪問者数と、サイトのトラフィックによって決定される）と、テストで確実に検出できる最小上昇率との間の適当なトレードオフを見つけるのに役立ちます。

![](assets/samplesizecontrol.png)

この例では、100 件のテスト中 80 件のテストで上昇率 5％（代替オファーのコンバージョン率（100％+5％）*5％ = 5.25％に相当）を検出できることが適切と判断できるので、各オファーのサンプルサイズとして 100,000 人の訪問者が必要です。このサイトには 1 日あたり 20,000 人の訪問者があり、2 つのオファーをテストする場合、代替オファーが制御オファーよりも統計的に有意に優れているかどうかを判断するには、テストを 2*100,000/20,000 = 10 日間実行できる必要があります。

前にも説明しましたが、必要な時間は常に直近の一週間に切り上げて、曜日効果を避けることをお勧めします。したがって、この例では、結果を見積もる前にテストは 2 週間実行されます。

### 訪問あたりの利益指標 {#section_C704C0861C9B4641AB02E911648D2DC2}

訪問あたりの利益（RPV）は、それぞれ独自の分散を持つ注文あたりの利益とコンバージョン率の積なので（RPV = 利益/訪問者数 =（注文あたりの利益 * 注文数）/訪問者数 = 注文あたりの利益 *（訪問者数 * CTR）/訪問者数 = 注文あたりの利益 * CTR）、RPV を指標として使用するときは、分散の追加ソースが追加されます。コンバージョン率の分散は、数学モデルを使用して直接見積もることができますが、注文あたりの売上高の分散はアクティビティに固有です。 したがって、過去のアクティビティからのこの分散の知識を使用するか、A/Bテストを数日間実行して売上高の分散を見積もります。 平方偏差は、CSVダウンロードファイルに含まれる訪問者の合計、売上合計の2乗および数の値から計算されます。 この設定が完了したら、スプレッドシートを使用してテストの完了に必要な時間を計算します。

サンプルサイズ計算ツール（上記のリンクを参照）は、RPV 指標の設定に役立ちます。When you open the calculator, you&#39;ll see a tab labeled [!UICONTROL RPV Metric]. RPV バージョンの計算ツールを使用する場合は、次の情報が必要になります。

* 制御オファーへの訪問者数
* 制御オファーの合計利益

   極端な注文のフィルターが選択されていることを確認します。

* 制御オファーの利益の平方和

   極端な注文のフィルターが有効になっていることを確認します。

一般に、RPVを指標として使用する場合、同じレベルの測定された上昇率に対して同じレベルの統計的信頼性を実現するには、20 ～ 30%長い時間が必要です。 これは、RPVには、コンバージョンごとに異なる注文サイズの差異が加わるからです。 これは、最終的なビジネス上の意思決定の基となる指標として、単純なコンバージョン率とRPVのどちらを選択するかを検討する際に考慮する必要があります。

## Correction for comparing multiple offers {#section_1474113764224D0B85472D8B023CCA15}

2 つのオファーを比較するたびに、偽陽性（コンバージョン率に違いがない場合でも、統計的に有意な違いを観察すること）が発生する可能性は有意水準と同じです。例えば、A／B／C／D／E の 5 つのオファーがあり、A が制御オファーの場合、 つの比較（制御オファーと B、制御オファーと C、制御オファーと D および制御オファーと E）がおこなわれ、信頼水準が 95％でも偽陽性の確率は 18.5％になります（Pr（少なくとも 1 つの偽陽性）= 1 - Pr（偽陽性なし）= 1 - 0.954 = 18.5％）。偽陽性は、代替オファーよりも優れていると報告される制御オファー、または制御オファーよりも優れていると報告される代替オファーのいずれかとして定義されるコンテキスト（実際は両方のオファーに違いはない）にあります。

## まとめ {#section_AEA2427B90AE4E9395C7FF4F9C5CA066}

[!UICONTROL 自動配分] アクティビティを使用すると、2つ以上のエクスペリエンスのうちの勝者を [!DNL Target] 識別し、テストの実行と学習を続ける間に、より多くのトラフィックを勝者に自動的に再割り当てして、コンバージョンを増やします。 [!UICONTROL 自動配分を使用すると、推測による作業を排除して、コンバージョン目標を簡単に達成できます。]

この記事で紹介したサンプルサイズ計算ツール（前述のリンク参照）を使用し、算出された時間に基づいてテストを実施すれば、特定のテストにふさわしいと判断された偽陽性率と偽陰性率に従って高品質な A/B テストを実施できます。その結果、テストは首尾一貫したものとなり、最適な上昇率を確実に検出することができます。
